{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efc2c2e2-102a-4143-b790-0799912ca60e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Developing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcc6f41c-00b3-4522-95df-170e7a8985c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Installing Dependancies and Configuring CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c8a9ef-0d98-42de-9607-bd60214627d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install databricks-cli mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c000941d-14d1-4956-9690-b88f811e790f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(\"/mnt/datamount/delta_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a09fb334-d0bc-4ffb-b744-9ee675c900de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open('tokenfile', 'w') as f:\n",
    "    f.write(dbutils.secrets.get(scope=\"tokens\", key=\"dbtoken\"))\n",
    "!databricks configure --host https://adb-6724577987585661.1.azuredatabricks.net/ --token-file tokenfile\n",
    "!rm -rf tokenfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aa3a20b-d78b-4cdc-8a77-ddd587b5af66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##MLFlow modelOps to train and register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b38a05e5-52e1-485d-9b99-dc4d3ec832e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "data = df.toPandas()\n",
    "\n",
    "# Define feature columns and target\n",
    "features = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "target = \"Survived\"\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlflow.set_experiment(\"/Users/bhaveshkak26122000@gmail.com/my_experiment\")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Train a machine learning model (Random Forest in this example)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # Create GridSearchCV with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate and log metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    mlflow.log_text(str(cm), \"confusion_matrix.txt\")\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "     # Log the best hyperparameters\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Save the feature columns for reference\n",
    "    mlflow.log_param(\"features\", features)\n",
    "\n",
    "    # Register the model in MLflow\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/model\"\n",
    "    registered_model_name = \"titanic_model\"\n",
    "\n",
    "    # Tags and Description\n",
    "    model_tags = {\n",
    "        \"Features\": \", \".join(features),\n",
    "        \"Label\": target,\n",
    "    }\n",
    "    model_description = \"Description of the registered model\"\n",
    "\n",
    "    # Register the model with MLflow\n",
    "    registered_model = mlflow.register_model(model_uri, registered_model_name, tags=model_tags)\n",
    "\n",
    "    # Print the registered model information\n",
    "    print(f\"Registered model: {registered_model.name} (Version {registered_model.version})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a424213-8fba-451e-9358-62c05f7c51f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Specify the experiment name and model name\n",
    "experiment_name = \"/Users/bhaveshkak26122000@gmail.com/my_experiment\"\n",
    "model_name = \"titanic_model\"\n",
    "\n",
    "# List all runs for the given experiment and model\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment_name], filter_string=f\"tags.ModelName = '{model_name}'\")\n",
    "\n",
    "# Print the available model versions and their run IDs\n",
    "for _, run in runs.iterrows():\n",
    "    print(f\"Run ID: {run.run_id}, Model Version: {run.artifact_uri.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e1017c3-499c-4c79-bc23-23eaea0f6da1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ML Part",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
